{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highlight 1.0078\n",
      "[{'role': <Role.SYSTEM: 'system'>, 'content': \"We're studying neurons in a neural network, and trying to identify their roles.Look at the parts/tokens of the document the neuron activates for and summarize in a single sentence what the neuron is looking for. Don't list examples of words.\\n\\n We will show short text excerpts, and highlight the tokens(part of word):that activate highly using stars, i.e. *token*. Your task is to summarize what highly activating tokens have in common, taking the context into account.\"}, {'role': <Role.USER: 'user'>, 'content': \"\\n\\nNeuron 1\\nActivations:\\n<start>\\n0 - Text excerpt:\\nturturro is fabulously funny and over the top as a 'very sneaky' butler who excels in the art of impossible* disappearing*/reapp*earing* acts\\n\\n<end>\\n<start>\\n1 - Text excerpt:\\nesc*aping** the* studio , piccoli is warmly* affecting* and so is this adroitly minimalist movie .\\n\\n<end>\\n\\nExplanation of neuron 1 behavior: the main thing this neuron does is find\"}, {'role': <Role.ASSISTANT: 'assistant'>, 'content': \" present tense verbs ending in 'ing'.\"}, {'role': <Role.USER: 'user'>, 'content': \"\\n\\nNeuron 2\\nActivations:\\n<start>\\n0 - Text excerpt:\\nas saccharine movies go , this is likely to cause massive cardiac* arrest* if taken in large doses .\\n\\n<end>\\n<start>\\n1 - Text excerpt:\\nshot perhaps 'artistically' with handheld cameras and apparently no movie lights by joaquin baca-asay , the low-budget production swings annoyingly between vert*igo* and opacity .\\n\\n<end>\\n\\nExplanation of neuron 2 behavior: the main thing this neuron does is find\"}, {'role': <Role.ASSISTANT: 'assistant'>, 'content': ' words related to physical medical conditions.'}, {'role': <Role.USER: 'user'>, 'content': \"\\n\\nNeuron 3\\nActivations:\\n<start>\\n0 - Text excerpt:\\nthe sense of together*ness* in our town is strong .\\n\\n<end>\\n<start>\\n1 - Text excerpt:\\na buoyant romantic comedy about friendship , love , and the truth that we*'re* all* in** this** together* .\\n\\n<end>\\n\\nExplanation of neuron 3 behavior: the main thing this neuron does is find\"}, {'role': <Role.ASSISTANT: 'assistant'>, 'content': ' phrases related to community.'}, {'role': <Role.USER: 'user'>, 'content': '\\n\\nNeuron 3\\nActivations:\\n<start>\\n0 - Text excerpt:\\n God give two men or* two* women a \"right\" to marry one another and then adopt children with the approval of the state? If two people of the same sex do have a right to marry and take custody of children, then, as this column argued last week, children cannot be deemed to have a right to a\\n\\n<end>\\n<start>\\n1 - Text excerpt:\\nhttp://archive.is/Hom3f\\n\\nalso of interest, the street address for james achilles, secretary of kidzworld.com and kidzwerld.com (two spellings,* two* different ip addresses) is shared by a shoddy looking massage parlour in vancouver -\\n\\n<end>\\n<start>\\n2 - Text excerpt:\\nformerly, previously, in the past, at one time,* at** one* point, once upon a time, on a former occasion, on one* occasion*,* one** time*, in* one* case,* time* was when, in days gone by,* in* times* gone* by, back in the day,* in** times* past,* in* the old days\\n\\n<end>\\n<start>\\n3 - Text excerpt:\\n (vanilla) or brown (chocolate). Sheet cakes and square cakes are best; you\\'ll need to cut off only the corner to announce your baby\\'s sex. If you\\'re expecting multiples, you could get a large sheet cake that is baked half and* half*, with clear delineation on the top for the\\n\\n<end>\\n<start>\\n4 - Text excerpt:\\n moment I\\'m laughing because I don\\'t want to cry â€“ I\\'m on the border. And that\\'s hard you know. We came here twice,* twice* we got beaten. Sydney have got seven points out of us\".\\n\\n\"But in the end there were four guys out there on $5000 wages. Can you\\n\\n<end>\\n\\nExplanation of neuron 3 behavior: the main thing this neuron does is find'}]\n",
      "explanation='instances where the number \"two\" is used or implied.'\n",
      "{'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}}\n",
      "Retrying after API error: The server had an error while processing your request. Sorry about that! (https://api.openai.com/v1/completions)\n",
      "{'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}}\n",
      "Retrying after API error: The server had an error while processing your request. Sorry about that! (https://api.openai.com/v1/completions)\n",
      "{'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}}\n",
      "Retrying after API error: The server had an error while processing your request. Sorry about that! (https://api.openai.com/v1/completions)\n",
      "score=0.33\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = open(os.path.join(os.path.expanduser(\"~\"), \".openai_api_key\"), \"r\").read()[:-1]\n",
    "\n",
    "from neuron_explainer.activations.activation_records import calculate_max_activation\n",
    "from neuron_explainer.activations.activations import ActivationRecordSliceParams, load_neuron\n",
    "from neuron_explainer.explanations.calibrated_simulator import UncalibratedNeuronSimulator\n",
    "from neuron_explainer.explanations.explainer import TokenActivationPairExplainer, SummaryExplainer, HighlightExplainer\n",
    "from neuron_explainer.explanations.prompt_builder import PromptFormat\n",
    "from neuron_explainer.explanations.scoring import simulate_and_score\n",
    "from neuron_explainer.explanations.simulator import ExplanationNeuronSimulator\n",
    "\n",
    "EXPLAINER_MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "SIMULATOR_MODEL_NAME = \"text-davinci-003\"\n",
    "MODE = \"Highlight\"#\"Original\"#\"Summary\"#\"Fixed\"#\"Highlight\"\n",
    "\n",
    "neuron_record = load_neuron(9, 6236)\n",
    "\n",
    "# Load a neuron record.\n",
    "\n",
    "cutoff = neuron_record.quantile_boundaries[2]\n",
    "print(MODE, cutoff)\n",
    "# Grab the activation records we'll need.\n",
    "slice_params = ActivationRecordSliceParams(n_examples_per_split=5)\n",
    "train_activation_records = neuron_record.train_activation_records(\n",
    "    activation_record_slice_params=slice_params\n",
    ")\n",
    "#uses a train\n",
    "\n",
    "valid_activation_records = neuron_record.valid_activation_records(\n",
    "    activation_record_slice_params=slice_params\n",
    ")\n",
    "\n",
    "if MODE==\"Summary\":\n",
    "    explainer = SummaryExplainer(\n",
    "        model_name=EXPLAINER_MODEL_NAME,\n",
    "        prompt_format=PromptFormat.HARMONY_V4,\n",
    "        max_concurrent=1,\n",
    "    )\n",
    "\n",
    "    explanations = await explainer.generate_explanations(\n",
    "        all_activation_records=train_activation_records,\n",
    "        cutoff=cutoff,\n",
    "        num_samples=1,\n",
    "    )\n",
    "    assert len(explanations) == 1\n",
    "    explanation = explanations[0]\n",
    "\n",
    "if MODE==\"Highlight\":\n",
    "    explainer = HighlightExplainer(\n",
    "        model_name=EXPLAINER_MODEL_NAME,\n",
    "        prompt_format=PromptFormat.HARMONY_V4,\n",
    "        max_concurrent=1,\n",
    "    )\n",
    "\n",
    "    explanations = await explainer.generate_explanations(\n",
    "        all_activation_records=train_activation_records,\n",
    "        cutoff=cutoff,\n",
    "        num_samples=1,\n",
    "    )\n",
    "    assert len(explanations) == 1\n",
    "    explanation = explanations[0]\n",
    "    \n",
    "    \n",
    "elif MODE==\"Original\":\n",
    "    explainer = TokenActivationPairExplainer(\n",
    "        model_name=EXPLAINER_MODEL_NAME,\n",
    "        prompt_format=PromptFormat.HARMONY_V4,\n",
    "        max_concurrent=1,\n",
    "    )\n",
    "    explanations = await explainer.generate_explanations(\n",
    "        all_activation_records=train_activation_records,\n",
    "        max_activation=calculate_max_activation(train_activation_records),\n",
    "        num_samples=1,\n",
    "    )\n",
    "    assert len(explanations) == 1\n",
    "    explanation = explanations[0]\n",
    "\n",
    "elif MODE==\"Fixed\":\n",
    "    explanation = \"transition words at the beginning of sentences.\"\n",
    "    \n",
    "print(f\"{explanation=}\")\n",
    "\n",
    "# Simulate and score the explanation.\n",
    "simulator = UncalibratedNeuronSimulator(\n",
    "    ExplanationNeuronSimulator(\n",
    "        SIMULATOR_MODEL_NAME,\n",
    "        explanation,\n",
    "        max_concurrent=1,\n",
    "        prompt_format=PromptFormat.INSTRUCTION_FOLLOWING,\n",
    "    )\n",
    ")\n",
    "scored_simulation = await simulate_and_score(simulator, valid_activation_records)\n",
    "print(f\"score={scored_simulation.get_preferred_score():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jovyan-milan]",
   "language": "python",
   "name": "conda-env-jovyan-milan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
